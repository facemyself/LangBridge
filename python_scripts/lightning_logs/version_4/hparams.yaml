n_gpu: 1
strategy: deepspeed_stage_2
eval_only: false
hf_checkpoint_path: null
enc_name_or_path: facebook/xglm-1.7B
lm_name_or_path: meta-math/MetaMath-7B-V1.0
alignments: linear
add_new_lines_to_enc: true
enc_hidden_size: 2048
lm_hidden_size: 4096
train_set_path: /data1/rzw/CODE/LangBridge/data/metamath-200k
val_set_path: null
limit_val_samples: null
output_exists: true
max_length: 128
max_length_enc: 1024
use_dynamic_enc_length: true
freeze_language_model: true
freeze_encoder: true
seed: 42
run_name: metamath-lb-9b
output_dir: checkpoints/metamath-lb-9b
save_total_limit: 5
save_interval: 1.0
check_val_every_n_epoch: 1
logging_steps: 10
dataloader_num_workers: 16
num_train_epochs: 1
learning_rate_alignment: 0.0006
learning_rate_enc: 2.0e-05
learning_rate_lm: 2.0e-05
w_decay_alignment: 0.0
w_decay_enc: 0.1
w_decay_lm: 0
warmup_steps: 0
per_device_train_batch_size: 4
per_device_eval_batch_size: 16
gradient_accumulation_steps: 8
gradient_clip_val: 1.0
bf16: true
